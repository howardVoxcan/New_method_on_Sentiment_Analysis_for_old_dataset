{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-10T02:55:44.123379Z",
     "iopub.status.busy": "2025-06-10T02:55:44.123018Z",
     "iopub.status.idle": "2025-06-10T02:55:48.213723Z",
     "shell.execute_reply": "2025-06-10T02:55:48.212376Z",
     "shell.execute_reply.started": "2025-06-10T02:55:44.123341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers google-generativeai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T02:56:13.015994Z",
     "iopub.status.busy": "2025-06-10T02:56:13.015210Z",
     "iopub.status.idle": "2025-06-10T02:56:13.581077Z",
     "shell.execute_reply": "2025-06-10T02:56:13.580058Z",
     "shell.execute_reply.started": "2025-06-10T02:56:13.015956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"df_train_clean.csv\")\n",
    "df_dev = pd.read_csv(\"df_dev_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T02:56:17.609075Z",
     "iopub.status.busy": "2025-06-10T02:56:17.608737Z",
     "iopub.status.idle": "2025-06-10T02:56:17.620315Z",
     "shell.execute_reply": "2025-06-10T02:56:17.619433Z",
     "shell.execute_reply.started": "2025-06-10T02:56:17.609052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>Constructiveness</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Title</th>\n",
       "      <th>Topic</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6326</td>\n",
       "      <td>Thật tuyệt vời...!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Những 'bước tiến diệu kỳ' của Trúc Nhi - Diệu Nhi</td>\n",
       "      <td>SucKhoe</td>\n",
       "      <td>Thật tuyệt vời...!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7835</td>\n",
       "      <td>mỹ đã tuột dốc quá nhiều rồi, giờ muốn vực dậy...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hình tượng Mỹ sụp đổ trong lòng người dân thế ...</td>\n",
       "      <td>TheGioi</td>\n",
       "      <td>mỹ đã tuột dốc quá nhiều rồi, giờ muốn vực dậy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4690</td>\n",
       "      <td>tôi thấy người lái xe hơi bấm còi mới là người...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cả trăm người đạp xe thể dục bịt kín đường</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>tôi thấy người lái xe hơi bấm còi mới là người...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6011</td>\n",
       "      <td>Coi dịch là giặc. Đã mang tên đó mà xâm nhập V...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11 ngày không lây nhiễm nCoV cộng đồng</td>\n",
       "      <td>SucKhoe</td>\n",
       "      <td>Coi dịch là giặc. Đã mang tên đó mà xâm nhập v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9303</td>\n",
       "      <td>Thương các bé quá! Các con còn quá nhỏ mà đã p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5 trẻ chết đuối dưới ao</td>\n",
       "      <td>ThoiSu</td>\n",
       "      <td>Thương các bé quá! Các con còn quá nhỏ mà đã p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  \\\n",
       "0        6326                               Thật tuyệt vời...!!!   \n",
       "1        7835  mỹ đã tuột dốc quá nhiều rồi, giờ muốn vực dậy...   \n",
       "2        4690  tôi thấy người lái xe hơi bấm còi mới là người...   \n",
       "3        6011  Coi dịch là giặc. Đã mang tên đó mà xâm nhập V...   \n",
       "4        9303  Thương các bé quá! Các con còn quá nhỏ mà đã p...   \n",
       "\n",
       "   Constructiveness  Toxicity  \\\n",
       "0                 0         0   \n",
       "1                 1         0   \n",
       "2                 1         1   \n",
       "3                 0         0   \n",
       "4                 0         0   \n",
       "\n",
       "                                               Title     Topic  \\\n",
       "0  Những 'bước tiến diệu kỳ' của Trúc Nhi - Diệu Nhi   SucKhoe   \n",
       "1  Hình tượng Mỹ sụp đổ trong lòng người dân thế ...   TheGioi   \n",
       "2         Cả trăm người đạp xe thể dục bịt kín đường  OtoXemay   \n",
       "3             11 ngày không lây nhiễm nCoV cộng đồng   SucKhoe   \n",
       "4                            5 trẻ chết đuối dưới ao    ThoiSu   \n",
       "\n",
       "                                       content_clean  \n",
       "0                               Thật tuyệt vời...!!!  \n",
       "1  mỹ đã tuột dốc quá nhiều rồi, giờ muốn vực dậy...  \n",
       "2  tôi thấy người lái xe hơi bấm còi mới là người...  \n",
       "3  Coi dịch là giặc. Đã mang tên đó mà xâm nhập v...  \n",
       "4  Thương các bé quá! Các con còn quá nhỏ mà đã p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T02:56:20.317810Z",
     "iopub.status.busy": "2025-06-10T02:56:20.317512Z",
     "iopub.status.idle": "2025-06-10T02:56:21.216517Z",
     "shell.execute_reply": "2025-06-10T02:56:21.215493Z",
     "shell.execute_reply.started": "2025-06-10T02:56:20.317790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import time\n",
    "from google.api_core.exceptions import TooManyRequests\n",
    "\n",
    "# Đặt API Key\n",
    "# genai.configure(api_key=\"AIzaSyCYyQsVZ8wbqrmLzol7Kg4DgyBs_c2xh8M\")  # Hoàng\n",
    "# genai.configure(api_key=\"AIzaSyBHvkNRmr7R8jAo2k27EbR4BpN8rsi9cA0\")  # Đạt\n",
    "genai.configure(api_key=\"AIzaSyCYIgyoJIld5XjVCp0TYiAIpoAWML6XQss\") #Hien\n",
    "\n",
    "# Chọn model Gemini Pro\n",
    "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
    "\n",
    "def classify_toxicity(text):\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là một hệ thống phân loại ngôn ngữ. Hãy phân loại câu sau thành một trong hai nhãn: \"toxic\" hoặc \"non-toxic\".\n",
    "    - \"toxic\" nếu câu chứa ngôn từ thô tục, xúc phạm, gây tổn thương, mang tính tiêu cực hoặc mang tính công kích.\n",
    "    - \"non-toxic\" nếu câu mang tính trung lập, tích cực, hoặc không chứa nội dung độc hại.\n",
    "\n",
    "    Trả về **chỉ một từ duy nhất** là \"toxic\" hoặc \"non-toxic\", không giải thích gì thêm.\n",
    "\n",
    "    Câu cần phân loại:\n",
    "    \"{text}\"\n",
    "    Nhãn:\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(6):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip().lower()\n",
    "        except TooManyRequests:\n",
    "            wait_time = 10\n",
    "            print(f\"Attempt {attempt+1}: Too many requests. Waiting {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý câu: {text}\\nChi tiết: {e}\")\n",
    "            return \"error\"\n",
    "    return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T02:57:08.452581Z",
     "iopub.status.busy": "2025-06-10T02:57:08.452096Z",
     "iopub.status.idle": "2025-06-10T05:27:06.161394Z",
     "shell.execute_reply": "2025-06-10T05:27:06.160373Z",
     "shell.execute_reply.started": "2025-06-10T02:57:08.452552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n"
     ]
    }
   ],
   "source": [
    "# Gộp dữ liệu train và dev\n",
    "df_train_LLM = pd.concat([df_train, df_dev], ignore_index=True)\n",
    "df_train_LLM = df_train_LLM.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Số lượng mẫu dùng để gán nhãn bằng LLM\n",
    "n = 150\n",
    "df_prompt_train = df_train_LLM.iloc[:n].copy()\n",
    "\n",
    "# Áp dụng mô hình Gemini để phân loại toxicity trên cột 'content_clean'\n",
    "df_prompt_train[\"toxicity_llm\"] = df_prompt_train[\"content_clean\"].apply(classify_toxicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T05:30:49.920741Z",
     "iopub.status.busy": "2025-06-10T05:30:49.920434Z",
     "iopub.status.idle": "2025-06-10T05:30:49.927523Z",
     "shell.execute_reply": "2025-06-10T05:30:49.926478Z",
     "shell.execute_reply.started": "2025-06-10T05:30:49.920717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_prompting(df):\n",
    "    # Ánh xạ chuỗi kết quả sang nhãn số\n",
    "    toxicity_map = {\"toxic\": 1, \"non-toxic\": 0}\n",
    "\n",
    "    # Gọi hàm prompting (trả về chuỗi như: \"toxic\" hoặc \"non-toxic\")\n",
    "    results = df['content_clean'].apply(classify_toxicity)\n",
    "\n",
    "    # Lưu kết quả thô để debug\n",
    "    df['raw_prompt'] = results\n",
    "\n",
    "    # Chuyển nhãn văn bản 'toxic' / 'non-toxic' thành nhãn số 1 / 0\n",
    "    label_map = {\"non-toxic\": 0, \"toxic\": 1}\n",
    "    df_prompt_train[\"toxicity_llm_label\"] = df_prompt_train[\"toxicity_llm\"].map(label_map)\n",
    "\n",
    "    # Chuyển thành nhãn số, và gán -1 cho các giá trị không ánh xạ được\n",
    "    df['toxicity_prompting'] = results.str.strip().map(toxicity_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T05:30:52.212726Z",
     "iopub.status.busy": "2025-06-10T05:30:52.212371Z",
     "iopub.status.idle": "2025-06-10T07:03:13.533517Z",
     "shell.execute_reply": "2025-06-10T07:03:13.532542Z",
     "shell.execute_reply.started": "2025-06-10T05:30:52.212702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Attempt 1: Too many requests. Waiting 10s...\n",
      "Attempt 2: Too many requests. Waiting 10s...\n",
      "Attempt 3: Too many requests. Waiting 10s...\n",
      "Attempt 4: Too many requests. Waiting 10s...\n",
      "Attempt 5: Too many requests. Waiting 10s...\n",
      "Tổng số mẫu: 150\n",
      "Số mẫu lỗi (NaN): 0\n"
     ]
    }
   ],
   "source": [
    "df_prompt_train = apply_prompting(df_prompt_train)\n",
    "\n",
    "# Giờ bạn có thể truy cập cột 'toxicity_prompting'\n",
    "print(\"Tổng số mẫu:\", len(df_prompt_train))\n",
    "print(\"Số mẫu lỗi (NaN):\", df_prompt_train['toxicity_prompting'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:24:19.540169Z",
     "iopub.status.busy": "2025-06-10T08:24:19.539859Z",
     "iopub.status.idle": "2025-06-10T08:24:21.595760Z",
     "shell.execute_reply": "2025-06-10T08:24:21.594365Z",
     "shell.execute_reply.started": "2025-06-10T08:24:19.540141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       126\n",
      "           1       0.45      0.38      0.41        24\n",
      "\n",
      "    accuracy                           0.83       150\n",
      "   macro avg       0.67      0.64      0.65       150\n",
      "weighted avg       0.82      0.83      0.82       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Bước 1: Gọi prompting để sinh nhãn toxicity từ LLM\n",
    "# apply_prompting(df_prompt_train)\n",
    "\n",
    "# Bước 2: Lưu toàn bộ kết quả zero-shot ra file\n",
    "df_prompt_train.to_csv(\"ZeroShot.csv\", index=False)\n",
    "\n",
    "# Bước 3: Loại bỏ các dòng lỗi (NaN) và ép kiểu\n",
    "df_valid = df_prompt_train.dropna(subset=['toxicity_prompting']).copy()\n",
    "df_valid.loc[:, 'toxicity_prompting'] = df_valid['toxicity_prompting'].astype(int)\n",
    "df_valid.loc[:, 'Toxicity'] = df_valid['Toxicity'].astype(int)\n",
    "\n",
    "# Bước 4: In báo cáo đánh giá\n",
    "print(classification_report(df_valid['Toxicity'], df_valid['toxicity_prompting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8846    0.9127    0.8984       126\n",
      "           1     0.4500    0.3750    0.4091        24\n",
      "\n",
      "    accuracy                         0.8267       150\n",
      "   macro avg     0.6673    0.6438    0.6538       150\n",
      "weighted avg     0.8151    0.8267    0.8201       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ZeroShot.csv\")\n",
    "\n",
    "print(classification_report(df['Toxicity'], df['toxicity_prompting'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:23.999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            content  \\\n",
      "0        8066  Mùa này mất suarez, từ bộ 3 MSN giờ còn mình M...   \n",
      "1        3333  khách hàng cũng tuyệt đối không cho ai ký thay...   \n",
      "2         506  Chạy bộ là một bộ môn đặc biệt lợi lạc cho sức...   \n",
      "3        8736  Đọc bình luận của mấy bác r7 vs m10 thấy tấu h...   \n",
      "4        7402  Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...   \n",
      "\n",
      "   Constructiveness  Toxicity  \\\n",
      "0                 0         0   \n",
      "1                 0         0   \n",
      "2                 1         0   \n",
      "3                 0         0   \n",
      "4                 0         0   \n",
      "\n",
      "                                               Title      Topic  \\\n",
      "0               20 năm Lionel Messi gắn bó với Barca    TheThao   \n",
      "1        Bỗng dưng mắc nợ ngân hàng dù không vay vốn  KinhDoanh   \n",
      "2             Ca sĩ Đăng Dương bơi, chạy bộ mỗi sáng    GiaiTri   \n",
      "3  Barnett: 'Real nên hôn lên sàn nhà nơi Bale đi...    TheThao   \n",
      "4  Cảnh sát đảo ngược kết luận vụ cô gái chết vì ...    TheGioi   \n",
      "\n",
      "                                       content_clean toxicity_llm raw_prompt  \\\n",
      "0  Mùa này mất suarez, từ bộ 3 MSN giờ còn mình M...    non-toxic  non-toxic   \n",
      "1  khách hàng z tuyệt đối không cho ai ký thay hồ...    non-toxic  non-toxic   \n",
      "2  Chạy bộ là một bộ môn đặc biệt lợi lạc cho sức...    non-toxic  non-toxic   \n",
      "3  Đọc bình luận của mấy bác r7 với m10 thấy tấu ...    non-toxic  non-toxic   \n",
      "4  Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...        toxic      toxic   \n",
      "\n",
      "   toxicity_llm_label  toxicity_prompting  \n",
      "0                   0                   0  \n",
      "1                   0                   0  \n",
      "2                   0                   0  \n",
      "3                   0                   0  \n",
      "4                   1                   1  \n"
     ]
    }
   ],
   "source": [
    "df_zero_shot = pd.read_csv(\"ZeroShot.csv\")\n",
    "\n",
    "print(df_zero_shot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                                            content  \\\n",
      "4         7402  Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...   \n",
      "9         4603  Chưa bao giờ đánh giá cao biem. Mec thì còn được.   \n",
      "11        4274  Cả hyundai i10 và vinfat fadli đều không đáng ...   \n",
      "16        3588  Điện thoại giá rẻ hay rác thải công nghiệp? Xu...   \n",
      "27        5695  trách cha đứa bé, thì trách chính quyền địa ph...   \n",
      "29        6396  NHìn nắp hộp, hộp là biết hàng không đảm bảo c...   \n",
      "33        8483  cũng mong chung bảng để barca hạ bayern trả nợ...   \n",
      "49         950  cứ li hôn là xấu, làm nghệ sĩ thì phải giữ hôn...   \n",
      "61        4615  BMW dạo này thiết kế mất chất quá, thua xa xe ...   \n",
      "62        5681  có hiếu hay bất hiếu đó là 1 định nghĩa không ...   \n",
      "\n",
      "    Constructiveness  Toxicity  \\\n",
      "4                  0         0   \n",
      "9                  0         1   \n",
      "11                 1         0   \n",
      "16                 1         1   \n",
      "27                 0         1   \n",
      "29                 1         0   \n",
      "33                 0         1   \n",
      "49                 1         1   \n",
      "61                 0         1   \n",
      "62                 1         1   \n",
      "\n",
      "                                                Title      Topic  \\\n",
      "4   Cảnh sát đảo ngược kết luận vụ cô gái chết vì ...    TheGioi   \n",
      "9      BMW bị phạt 18 triệu USD vì báo khống doanh số   OtoXemay   \n",
      "11   400 triệu nên mua Hyundai i10 hay VinFast Fadil?   OtoXemay   \n",
      "16          Chiến lược 'thu nhỏ' của Thế giới Di Động  KinhDoanh   \n",
      "27            Bé trai 4 năm sống trong đòn roi của bố   PhapLuat   \n",
      "29        7 người ngộ độc pate Minh Chay phải thở máy    SucKhoe   \n",
      "33  Barca có thể chung bảng Bayern ở Champions League    TheThao   \n",
      "49                      Diễn viên Thanh Sơn đã ly hôn    GiaiTri   \n",
      "61            BMW series 4 Coupe 2021 nâng cấp ra mắt   OtoXemay   \n",
      "62             Bất hiếu - trọng tội dưới triều Nguyễn   PhapLuat   \n",
      "\n",
      "                                        content_clean toxicity_llm raw_prompt  \\\n",
      "4   Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...        toxic      toxic   \n",
      "9   Chưa bao giờ đánh giá cao biem. Mec thì còn được.    non-toxic  non-toxic   \n",
      "11  Cả hyundai i10 và vinfat fadli đều không đáng ...        toxic      toxic   \n",
      "16  Điện thoại giá rẻ hay rác thải công nghiệp? Xu...    non-toxic  non-toxic   \n",
      "27  trách cha đứa bé, thì trách chính quyền địa ph...    non-toxic  non-toxic   \n",
      "29  NHìn nắp hộp, hộp là biết hàng không đảm bảo c...        toxic      toxic   \n",
      "33  z mong chung bảng để barca hạ bayern trả nợ, c...    non-toxic  non-toxic   \n",
      "49  cứ li hôn là xấu, làm nghệ sĩ thì phải giữ hôn...    non-toxic  non-toxic   \n",
      "61  BMW dạo này thiết kế mất chất quá, thua xa xe ...    non-toxic  non-toxic   \n",
      "62  có hiếu hay bất hiếu đó là 1 định nghĩa không ...    non-toxic  non-toxic   \n",
      "\n",
      "    toxicity_llm_label  toxicity_prompting  \n",
      "4                    1                   1  \n",
      "9                    0                   0  \n",
      "11                   1                   1  \n",
      "16                   0                   0  \n",
      "27                   0                   0  \n",
      "29                   1                   1  \n",
      "33                   0                   0  \n",
      "49                   0                   0  \n",
      "61                   0                   0  \n",
      "62                   0                   0  \n"
     ]
    }
   ],
   "source": [
    "df_wrong_toxicity = df_zero_shot[df_zero_shot['Toxicity'] != df_zero_shot['toxicity_prompting']]\n",
    "print(df_wrong_toxicity.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong toxicity:  (26, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Wrong toxicity: \", df_wrong_toxicity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_wrong_toxicity = df_wrong_toxicity.copy()  # Tạo bản sao thực sự\n",
    "df_wrong_toxicity.drop(columns=[\"content_clean\"], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0            0\n",
      "content               0\n",
      "Constructiveness      0\n",
      "Toxicity              0\n",
      "Title                 0\n",
      "Topic                 0\n",
      "toxicity_llm          0\n",
      "raw_prompt            0\n",
      "toxicity_llm_label    0\n",
      "toxicity_prompting    0\n",
      "dtype: int64\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Kiểm tra có giá trị NaN không\n",
    "print(df_wrong_toxicity.isna().sum())\n",
    "\n",
    "# Kiểm tra giá trị vô hạn\n",
    "print(np.isinf(df_wrong_toxicity.select_dtypes(include=[float])).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>Constructiveness</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Title</th>\n",
       "      <th>Topic</th>\n",
       "      <th>toxicity_llm</th>\n",
       "      <th>raw_prompt</th>\n",
       "      <th>toxicity_llm_label</th>\n",
       "      <th>toxicity_prompting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7402</td>\n",
       "      <td>Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cảnh sát đảo ngược kết luận vụ cô gái chết vì ...</td>\n",
       "      <td>TheGioi</td>\n",
       "      <td>toxic</td>\n",
       "      <td>toxic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4603</td>\n",
       "      <td>Chưa bao giờ đánh giá cao biem. Mec thì còn được.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BMW bị phạt 18 triệu USD vì báo khống doanh số</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4274</td>\n",
       "      <td>Cả hyundai i10 và vinfat fadli đều không đáng ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>400 triệu nên mua Hyundai i10 hay VinFast Fadil?</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>toxic</td>\n",
       "      <td>toxic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3588</td>\n",
       "      <td>Điện thoại giá rẻ hay rác thải công nghiệp? Xu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiến lược 'thu nhỏ' của Thế giới Di Động</td>\n",
       "      <td>KinhDoanh</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5695</td>\n",
       "      <td>trách cha đứa bé, thì trách chính quyền địa ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bé trai 4 năm sống trong đòn roi của bố</td>\n",
       "      <td>PhapLuat</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                            content  \\\n",
       "4         7402  Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp...   \n",
       "9         4603  Chưa bao giờ đánh giá cao biem. Mec thì còn được.   \n",
       "11        4274  Cả hyundai i10 và vinfat fadli đều không đáng ...   \n",
       "16        3588  Điện thoại giá rẻ hay rác thải công nghiệp? Xu...   \n",
       "27        5695  trách cha đứa bé, thì trách chính quyền địa ph...   \n",
       "\n",
       "    Constructiveness  Toxicity  \\\n",
       "4                  0         0   \n",
       "9                  0         1   \n",
       "11                 1         0   \n",
       "16                 1         1   \n",
       "27                 0         1   \n",
       "\n",
       "                                                Title      Topic toxicity_llm  \\\n",
       "4   Cảnh sát đảo ngược kết luận vụ cô gái chết vì ...    TheGioi        toxic   \n",
       "9      BMW bị phạt 18 triệu USD vì báo khống doanh số   OtoXemay    non-toxic   \n",
       "11   400 triệu nên mua Hyundai i10 hay VinFast Fadil?   OtoXemay        toxic   \n",
       "16          Chiến lược 'thu nhỏ' của Thế giới Di Động  KinhDoanh    non-toxic   \n",
       "27            Bé trai 4 năm sống trong đòn roi của bố   PhapLuat    non-toxic   \n",
       "\n",
       "   raw_prompt  toxicity_llm_label  toxicity_prompting  \n",
       "4       toxic                   1                   1  \n",
       "9   non-toxic                   0                   0  \n",
       "11      toxic                   1                   1  \n",
       "16  non-toxic                   0                   0  \n",
       "27  non-toxic                   0                   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong_toxicity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_toxicity_few(text):\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là một hệ thống phân loại ngôn ngữ. Hãy phân loại câu sau thành một trong hai nhãn: \"toxic\" hoặc \"non-toxic\".\n",
    "    - \"toxic\" nếu câu chứa ngôn từ thô tục, xúc phạm, gây tổn thương, mang tính tiêu cực hoặc mang tính công kích.\n",
    "    - \"non-toxic\" nếu câu mang tính trung lập, tích cực, hoặc không chứa nội dung độc hại.\n",
    "\n",
    "    Trả về **chỉ một từ duy nhất** là \"toxic\" hoặc \"non-toxic\", không giải thích gì thêm.\n",
    "\n",
    "    Ví dụ 1\n",
    "    \"Ấn Độ, nơi khủng khiếp mà phụ nữ tầng lớp thấp phải đối mặt.\"\n",
    "    → Câu nêu thực trạng khó khăn mà một nhóm người phải trải qua, dùng ngôn ngữ mạnh để nhấn mạnh mức độ nghiêm trọng, nhưng không nhằm công kích hay xúc phạm cá nhân cụ thể. Đây là nhận định mang tính phản ánh xã hội.\n",
    "    → non-toxic\n",
    "\n",
    "    Ví dụ 2\n",
    "    \"Chưa bao giờ đánh giá cao biem. Mec thì còn được.\"\n",
    "    → Câu thể hiện thái độ phủ định mạnh mẽ với một thương hiệu cụ thể (biem), mang tính xem thường. Việc nói \"chưa bao giờ đánh giá cao\" mà không đưa ra lý do cụ thể khiến câu có thể bị hiểu là chê bai một cách cảm tính.\n",
    "    → toxic\n",
    "\n",
    "    Ví dụ 3\n",
    "    \"Cả hyundai i10 và vinfat fadli đều không đáng mua ở mức giá 400 triệu. Rất nhiều xe tầm tiền tốt hơn hẳn bạn nên tìm hiểu thêm, đừng có rước fadli hay i10 sedan nhìn hai chiếc xe chả ra làm sao cả.\"\n",
    "    → Câu thể hiện quan điểm cá nhân trong việc lựa chọn xe, dù ngữ điệu có phần mạnh nhưng không dùng từ ngữ xúc phạm cá nhân hay công kích nặng nề; mang tính khuyến nghị người mua nên tìm hiểu kỹ hơn.\n",
    "    → non-toxic\n",
    "\n",
    "    Ví dụ 4\n",
    "    \"Điện thoại giá rẻ hay rác thải công nghiệp? Xu thế thương mại điện tử là sự thay thế tất yếu cho hệ thống cửa hàng phân phối. Hệ thống cửa hàng chỉ có tác dụng lấn át đối thủ mà thôi. Doanh nghiệp cần linh động quy mô hoạt động để có thể tồn tại khi thị trường bảo hoà và cạnh tranh gay gắt.\"\n",
    "    → Câu mở đầu với cách ví điện thoại giá rẻ như \"rác thải công nghiệp\", mang tính miệt thị nặng đối với phân khúc sản phẩm và cả nhóm người tiêu dùng sử dụng nó. Cách diễn đạt này có thể được xem là xúc phạm và thiếu tôn trọng.\n",
    "    → toxic\n",
    "\n",
    "    Ví dụ 5\n",
    "    \"trách cha đứa bé, thì trách chính quyền địa phương quá vô tâm,\"\n",
    "    → Câu chứa nội dung chỉ trích mạnh cá nhân và chính quyền với giọng điệu lên án, thiếu tính trung lập.\n",
    "    → toxic\n",
    "\n",
    "    Câu cần phân loại:\n",
    "    \"{text}\"\n",
    "    Nhãn:\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(6):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip().lower()\n",
    "        except TooManyRequests:\n",
    "            wait_time = 10\n",
    "            print(f\"Attempt: {attempt}\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Unidentified error with input: {text}\\n{e}\")\n",
    "            return \"error\"\n",
    "    return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>Constructiveness</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Title</th>\n",
       "      <th>Topic</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6252</td>\n",
       "      <td>Người ăn không hết kẻ lần chẳng ra</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28 năm chịu đựng bộ ngực khổng lồ</td>\n",
       "      <td>SucKhoe</td>\n",
       "      <td>Người ăn không hết kẻ lần chẳng ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4684</td>\n",
       "      <td>Nhiều người cứ nghĩ đạp xe là văn minh. haizzzz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cả trăm người đạp xe thể dục bịt kín đường</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>Nhiều người cứ nghĩ đạp xe là văn minh. haiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1731</td>\n",
       "      <td>Rất văn hoá</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cô gái được bố nhắn nhủ ba từ mỗi ngày</td>\n",
       "      <td>GiaoDuc</td>\n",
       "      <td>Rất văn hoá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4742</td>\n",
       "      <td>Đời ta ba mươi đời nó. Mua chiếc xe cũng chỉ p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Các loại phụ kiện ôtô đại lý hay chào khách</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>Đời ta ba mươi đời nó. Mua chiếc xe z chỉ phục...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4521</td>\n",
       "      <td>Tước bằng lái vĩnh viễn đi. Chạy lếu láo thật,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ba người thoát chết dưới bánh xe bồn</td>\n",
       "      <td>OtoXemay</td>\n",
       "      <td>Tước bằng lái vĩnh viễn đi. Chạy lếu láo thật,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  \\\n",
       "0        6252                 Người ăn không hết kẻ lần chẳng ra   \n",
       "1        4684    Nhiều người cứ nghĩ đạp xe là văn minh. haizzzz   \n",
       "2        1731                                        Rất văn hoá   \n",
       "3        4742  Đời ta ba mươi đời nó. Mua chiếc xe cũng chỉ p...   \n",
       "4        4521  Tước bằng lái vĩnh viễn đi. Chạy lếu láo thật,...   \n",
       "\n",
       "   Constructiveness  Toxicity                                        Title  \\\n",
       "0                 0         1            28 năm chịu đựng bộ ngực khổng lồ   \n",
       "1                 0         1   Cả trăm người đạp xe thể dục bịt kín đường   \n",
       "2                 0         0       Cô gái được bố nhắn nhủ ba từ mỗi ngày   \n",
       "3                 0         0  Các loại phụ kiện ôtô đại lý hay chào khách   \n",
       "4                 1         1         Ba người thoát chết dưới bánh xe bồn   \n",
       "\n",
       "      Topic                                      content_clean  \n",
       "0   SucKhoe                 Người ăn không hết kẻ lần chẳng ra  \n",
       "1  OtoXemay       Nhiều người cứ nghĩ đạp xe là văn minh. haiz  \n",
       "2   GiaoDuc                                        Rất văn hoá  \n",
       "3  OtoXemay  Đời ta ba mươi đời nó. Mua chiếc xe z chỉ phục...  \n",
       "4  OtoXemay  Tước bằng lái vĩnh viễn đi. Chạy lếu láo thật,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"df_test_clean.csv\").head(300)\n",
    "df_test.shape\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_prompting_few(df):\n",
    "    # Gọi hàm phân loại zero-shot\n",
    "    results = df['content_clean'].apply(classify_toxicity_few)\n",
    "\n",
    "    # Ghi lại kết quả raw để debug nếu cần\n",
    "    df['raw_prompt'] = results\n",
    "\n",
    "    # Map về nhãn số: non-toxic → 0, toxic → 1\n",
    "    label_map = {'non-toxic': 0, 'toxic': 1}\n",
    "    df['toxicity_prompting'] = results.map(label_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Attempt: 0\n",
      "Attempt: 1\n",
      "Attempt: 2\n",
      "Attempt: 3\n",
      "Attempt: 4\n",
      "Attempt: 5\n",
      "Số prompt không hợp lệ: 58\n",
      "                                         content_clean raw_prompt\n",
      "242           Người ta giáo dục con em trong gia đình?      error\n",
      "243  Về việt nam thì giá bằng bao nhiêu lần 70.0usd...      error\n",
      "244  Đã vào đến chung kết thì em nào z có cơ hội vô...      error\n",
      "245  em này đúng là rất nhưng cái giỏi của em này l...      error\n",
      "246   Không hiểu thế nào mà mua cái loại đó mà ăn được      error\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm prompting\n",
    "df_test = apply_prompting_few(df_test)\n",
    "invalid_vals = df_test[~df_test['raw_prompt'].isin(['toxic', 'non-toxic'])]\n",
    "print(\"Số prompt không hợp lệ:\", len(invalid_vals))\n",
    "print(invalid_vals[['content_clean', 'raw_prompt']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-10T02:54:24.001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       212\n",
      "           1       0.39      0.57      0.46        30\n",
      "\n",
      "    accuracy                           0.83       242\n",
      "   macro avg       0.66      0.72      0.68       242\n",
      "weighted avg       0.87      0.83      0.85       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chỉ giữ lại các dòng dự đoán hợp lệ\n",
    "df_eval = df_test[df_test['toxicity_prompting'].notna()]\n",
    "\n",
    "df_test.to_csv(\"result.csv\", index = False)\n",
    "\n",
    "# In báo cáo phân loại\n",
    "print(classification_report(df_eval['Toxicity'].astype(int),\n",
    "                            df_eval['toxicity_prompting'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9343    0.8726    0.9024       212\n",
      "           1     0.3864    0.5667    0.4595        30\n",
      "\n",
      "    accuracy                         0.8347       242\n",
      "   macro avg     0.6604    0.7197    0.6809       242\n",
      "weighted avg     0.8664    0.8347    0.8475       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"result.csv\")\n",
    "\n",
    "# Loại bỏ các hàng có NaN trong 2 cột cần so sánh\n",
    "df_clean = df.dropna(subset=['Toxicity', 'toxicity_prompting'])\n",
    "\n",
    "print(classification_report(df_clean['Toxicity'], df_clean['toxicity_prompting'], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7520455,
     "sourceId": 12079661,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
